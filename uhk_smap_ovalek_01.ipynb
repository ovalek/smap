{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UHK SMAP ovalek 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in /usr/lib64/python3.10/site-packages (1.22.0)\n",
      "Requirement already satisfied: pandas in /home/ovalek/.local/lib/python3.10/site-packages (1.5.2)\n",
      "Requirement already satisfied: tensorflow in /home/ovalek/.local/lib/python3.10/site-packages (2.11.0)\n",
      "Requirement already satisfied: tensorflow_datasets in /home/ovalek/.local/lib/python3.10/site-packages (4.7.0)\n",
      "Requirement already satisfied: scikit-learn in /home/ovalek/.local/lib/python3.10/site-packages (1.2.0)\n",
      "Requirement already satisfied: scipy in /home/ovalek/.local/lib/python3.10/site-packages (1.9.3)\n",
      "Requirement already satisfied: matplotlib in /home/ovalek/.local/lib/python3.10/site-packages (3.6.2)\n",
      "Requirement already satisfied: tensorflow_io in /home/ovalek/.local/lib/python3.10/site-packages (0.28.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3.10/site-packages (from pandas) (2022.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ovalek/.local/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in /home/ovalek/.local/lib/python3.10/site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: packaging in /usr/lib/python3.10/site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in /home/ovalek/.local/lib/python3.10/site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/ovalek/.local/lib/python3.10/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /home/ovalek/.local/lib/python3.10/site-packages (from tensorflow) (22.12.6)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/ovalek/.local/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/ovalek/.local/lib/python3.10/site-packages (from tensorflow) (4.4.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/ovalek/.local/lib/python3.10/site-packages (from tensorflow) (2.1.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/ovalek/.local/lib/python3.10/site-packages (from tensorflow) (14.0.6)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/ovalek/.local/lib/python3.10/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/ovalek/.local/lib/python3.10/site-packages (from tensorflow) (3.19.6)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/ovalek/.local/lib/python3.10/site-packages (from tensorflow) (1.51.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/ovalek/.local/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /home/ovalek/.local/lib/python3.10/site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/ovalek/.local/lib/python3.10/site-packages (from tensorflow) (0.28.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/ovalek/.local/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/ovalek/.local/lib/python3.10/site-packages (from tensorflow) (1.3.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/ovalek/.local/lib/python3.10/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3.10/site-packages (from tensorflow) (59.6.0)\n",
      "Requirement already satisfied: tqdm in /usr/lib/python3.10/site-packages (from tensorflow_datasets) (4.64.1)\n",
      "Requirement already satisfied: tensorflow-metadata in /home/ovalek/.local/lib/python3.10/site-packages (from tensorflow_datasets) (1.12.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/lib/python3.10/site-packages (from tensorflow_datasets) (2.27.1)\n",
      "Requirement already satisfied: promise in /home/ovalek/.local/lib/python3.10/site-packages (from tensorflow_datasets) (2.3)\n",
      "Requirement already satisfied: dill in /home/ovalek/.local/lib/python3.10/site-packages (from tensorflow_datasets) (0.3.6)\n",
      "Requirement already satisfied: etils[epath] in /home/ovalek/.local/lib/python3.10/site-packages (from tensorflow_datasets) (0.9.0)\n",
      "Requirement already satisfied: toml in /home/ovalek/.local/lib/python3.10/site-packages (from tensorflow_datasets) (0.10.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ovalek/.local/lib/python3.10/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/ovalek/.local/lib/python3.10/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/lib/python3.10/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ovalek/.local/lib/python3.10/site-packages (from matplotlib) (1.0.6)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ovalek/.local/lib/python3.10/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ovalek/.local/lib/python3.10/site-packages (from matplotlib) (4.38.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ovalek/.local/lib/python3.10/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/lib64/python3.10/site-packages (from matplotlib) (9.1.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/ovalek/.local/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets) (2.0.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/ovalek/.local/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/ovalek/.local/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ovalek/.local/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/ovalek/.local/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/ovalek/.local/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/ovalek/.local/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: zipp in /home/ovalek/.local/lib/python3.10/site-packages (from etils[epath]->tensorflow_datasets) (3.11.0)\n",
      "Requirement already satisfied: importlib_resources in /home/ovalek/.local/lib/python3.10/site-packages (from etils[epath]->tensorflow_datasets) (5.10.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /home/ovalek/.local/lib/python3.10/site-packages (from tensorflow-metadata->tensorflow_datasets) (1.57.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/ovalek/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ovalek/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ovalek/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ovalek/.local/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/ovalek/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ovalek/.local/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ovalek/.local/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# install packages\n",
    "%pip install numpy pandas tensorflow tensorflow_datasets scikit-learn scipy matplotlib tensorflow_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['small', 'photos_sanitized.csv', 'parameters_products_color_sanitized.csv', 'tmp_dataset', 'parameters_list_sanitized.csv', 'parameters_products_pattern_sanitized.csv']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "print(os.listdir(\"./data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-14 07:38:36.329340: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-14 07:38:36.621683: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-14 07:38:36.621702: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-14 07:38:37.489282: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-14 07:38:37.489339: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-14 07:38:37.489345: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-14 07:38:38.459608: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-14 07:38:38.459870: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-14 07:38:38.459920: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-14 07:38:38.459957: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-14 07:38:38.459992: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-12-14 07:38:38.460027: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-12-14 07:38:38.460061: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-14 07:38:38.460232: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-14 07:38:38.460277: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-12-14 07:38:38.460283: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# check GPU\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names are id_product, id_photo, date_update, position, show_in_lead\n",
      "Processed 16161 lines.\n",
      "Found products <method-wrapper '__len__' of list object at 0x7f21fa56a100>.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "\n",
    "# load labels\n",
    "label_ids = []\n",
    "label_names = []\n",
    "with open('./data/parameters_list_sanitized.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        if line_count == 0:\n",
    "            line_count += 1\n",
    "            continue\n",
    "        else:\n",
    "            line_count += 1\n",
    "            if not row[0] in label_ids:\n",
    "                label_ids += [row[0]]\n",
    "                label_names += [row[2]]\n",
    "\n",
    "# load product label relations\n",
    "products_labels = {}\n",
    "with open('./data/parameters_products_color_sanitized.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        if line_count == 0:\n",
    "            line_count += 1\n",
    "            continue\n",
    "        else:\n",
    "            line_count += 1\n",
    "            if not row[0] in products_labels:\n",
    "                products_labels[row[0]] = []\n",
    "            for label_index, label_id in enumerate(label_ids):\n",
    "                if label_id == row[2]:\n",
    "                    products_labels[row[0]] += [label_names[label_index]]\n",
    "with open('./data/parameters_products_pattern_sanitized.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        if line_count == 0:\n",
    "            line_count += 1\n",
    "            continue\n",
    "        else:\n",
    "            line_count += 1\n",
    "            if not row[0] in products_labels:\n",
    "                products_labels[row[0]] = []\n",
    "            for label_index, label_id in enumerate(label_ids):\n",
    "                if label_id == row[2]:\n",
    "                    products_labels[row[0]] += [label_names[label_index]]\n",
    "\n",
    "# load products with main photo\n",
    "products = []\n",
    "with open('./data/photos_sanitized.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        if line_count == 0:\n",
    "            print(f'Column names are {\", \".join(row)}')\n",
    "            line_count += 1\n",
    "        else:\n",
    "            line_count += 1\n",
    "            if row[4] != 'Y':\n",
    "                continue\n",
    "            found = False\n",
    "            for product in products:\n",
    "                if product[0] == row[0]:\n",
    "                    found = True\n",
    "                    break\n",
    "            if not found:\n",
    "                products += [(row[0], row[1], row[3], row[4], ), ]\n",
    "    print(f'Processed {line_count} lines.')\n",
    "    print(f'Found products {products.__len__}.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import exists\n",
    "from PIL import Image\n",
    "import imghdr\n",
    "\n",
    "# prepare data for dataset\n",
    "data_photos_paths = []\n",
    "data_labels = []\n",
    "img_type_accepted_by_tf = [\"bmp\", \"gif\", \"jpeg\", \"png\"]\n",
    "for product in products:\n",
    "    tmp_path = f'./data/small/{int(product[0]) % 10}/{product[0]}/{product[0]}_{product[1]}_{product[3]}_{product[2]}_small.webp'\n",
    "    tmp_path_jpg = f'./data/small/{int(product[0]) % 10}/{product[0]}/{product[0]}_{product[1]}_{product[3]}_{product[2]}_small.jpg'\n",
    "    if not exists(tmp_path):\n",
    "        continue\n",
    "    if not exists(tmp_path_jpg) and os.stat(tmp_path).st_size == 0:\n",
    "        print(f'Empty file: {tmp_path}')\n",
    "        continue\n",
    "    if not exists(tmp_path_jpg):\n",
    "        im = Image.open(tmp_path).convert('RGB')\n",
    "        im.save(tmp_path_jpg, \"jpeg\")\n",
    "\n",
    "    img_type = imghdr.what(tmp_path_jpg)\n",
    "    if img_type is None:\n",
    "        print(f\"{tmp_path_jpg} is not an image\")\n",
    "        continue\n",
    "\n",
    "    data_photos_paths += [tmp_path_jpg]\n",
    "    tmp_product_labels = products_labels[product[0]]\n",
    "    tmp_labels_vector = []\n",
    "    for label in label_names:\n",
    "        tmp_labels_vector += [1 if label in tmp_product_labels else 0]\n",
    "    data_labels += [tmp_labels_vector]\n",
    "    # for label_index, label_name in enumerate(label_names):\n",
    "    #     if label_name == tmp_product_labels[0]:\n",
    "    #         data_labels += [label_index]\n",
    "    #         break\n",
    "\n",
    "# print(', '.join(data_labels[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare train test and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-14 07:38:42.677118: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow_io as tfio\n",
    "\n",
    "data_photos_paths_train, data_photos_paths_tmp, data_labels_train, data_labels_tmp = train_test_split(data_photos_paths, data_labels, test_size=0.25, random_state=42)\n",
    "data_photos_paths_test, data_photos_paths_validation, data_labels_test, data_labels_validation = train_test_split(data_photos_paths_tmp, data_labels_tmp, test_size=0.4, random_state=None, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "def _create_dataset(X, y):\n",
    "    # X = tf.constant(X)\n",
    "    # y = tf.constant(y)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "\n",
    "    def _prepare_picture_func(picturepath, labels):\n",
    "        image_string = tf.io.read_file(picturepath)\n",
    "        image = tf.image.decode_image(image_string, channels=3)\n",
    "        # print(picturepath)\n",
    "        # image = tfio.image.decode_webp(image_string)\n",
    "        # image = image[:,:,:3] # discard alpha channel\n",
    "        image.set_shape([None, None, None])\n",
    "        image = tf.image.resize(image, [250, 340])\n",
    "        # image = tf.subtract(image, 116.779) # Zero-center by mean pixel\n",
    "        # # image.set_shape([200, 200, 3])\n",
    "        # image.set_shape((250, 250, 3))\n",
    "        image.set_shape((250, 340, 3))\n",
    "        # image = image.reshape(-1, 250, 340, 3)\n",
    "        # image = tf.reverse(image, axis=[2]) # 'RGB'->'BGR'\n",
    "        # d = dict(zip([picturepath], [image])), labels\n",
    "        # return (picturepath, image), labels\n",
    "        return image, labels\n",
    "        # return d\n",
    "    return dataset.map(_prepare_picture_func)\n",
    "\n",
    "train_ds = _create_dataset(data_photos_paths_train, data_labels_train)\n",
    "test_ds = _create_dataset(data_photos_paths_test, data_labels_test)\n",
    "validation_ds = _create_dataset(data_photos_paths_validation, data_labels_validation)\n",
    "\n",
    "\n",
    "# data_photos_paths = tf.constant(data_photos_paths)\n",
    "# data_labels = tf.constant(data_labels)\n",
    "# dataset = tf.data.Dataset.from_tensor_slices((data_photos_paths, data_labels))\n",
    "\n",
    "# def _prepare_picture_func(picturepath, labels):\n",
    "#     image_string = tf.io.read_file(picturepath)\n",
    "#     image = tf.image.decode_image(image_string, channels=3)\n",
    "#     image.set_shape([None, None, None])\n",
    "#     image = tf.image.resize(image, [150, 150])\n",
    "#     image = tf.subtract(image, 116.779) # Zero-center by mean pixel\n",
    "#     image.set_shape([150, 150, 3])\n",
    "#     # image = tf.reverse(image, axis=[2]) # 'RGB'->'BGR'\n",
    "#     # d = dict(zip([picturepath], [image])), labels\n",
    "#     return (picturepath, image), labels\n",
    "#     # return d\n",
    "# dataset = dataset.map(_prepare_picture_func)\n",
    "\n",
    "\n",
    "\n",
    "# import tensorflow_datasets as tfds\n",
    "\n",
    "# dataset = dataset.shuffle(buffer_size=100, seed=19575364)\n",
    "# dataset.save('./data/tmp_dataset')\n",
    "\n",
    "\n",
    "\n",
    "# train_set, test_set, valid_set = tfds.load('./data/tmp_dataset', \n",
    "#                                            split=[\"train[0%:75%]\", \"test[75%:90%]\", \"valid[90%:100%]\"],\n",
    "#                                            as_supervised=True, with_info=True, download=False)\n",
    "\n",
    "#batch = dataset.batch(20)\n",
    "\n",
    "\n",
    "# train_set, tmp_set = tf.keras.utils.split_dataset(\n",
    "#     dataset, left_size=0.75, right_size=0.25, shuffle=True, seed=19575364\n",
    "# )\n",
    "# test_set, valid_set = tf.keras.utils.split_dataset(\n",
    "#     dataset, left_size=0.60, right_size=0.40, shuffle=False, seed=None\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_batch = train_ds.batch(32)\n",
    "# test_batch = test_ds.batch(32)\n",
    "\n",
    "# # check batch\n",
    "# for image_batch, labels_batch in train_batch:\n",
    "#   print(image_batch.shape)\n",
    "#   print(labels_batch.shape)\n",
    "#   break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "\n",
    "# # Initializes a sequential model\n",
    "# model = Sequential()\n",
    "\n",
    "# # First layer (pictures are 240x340=85000 x 3 colors => 255000)\n",
    "# # model.add(Dense(2048, activation='relu', input_shape=(255000, )))\n",
    "# model.add(Dense(2048, activation='relu', input_shape=(250, 250, 3)))\n",
    "# # model.add(Dense(2048, activation='relu', input_shape=(187500, )))\n",
    "# # model.add(Dense(2048, activation='relu', input_dim=187500))\n",
    "\n",
    "# # Second layer\n",
    "# model.add(Dense(256, activation='relu'))\n",
    "\n",
    "# # Output layer (multi-label classification therefore use sigmoid activation function)\n",
    "# model.add(Dense(48, activation='sigmoid'))\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "\n",
    "num_classes = len(label_names)\n",
    "\n",
    "model = Sequential([\n",
    "  layers.Rescaling(1./255, input_shape=(250, 340, 3)),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='sigmoid'),\n",
    "  # layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "  # layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling (Rescaling)       (None, 250, 340, 3)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 250, 340, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 125, 170, 16)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 125, 170, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 62, 85, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 62, 85, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 31, 42, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 83328)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               10666112  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 48)                6192      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,695,888\n",
      "Trainable params: 10,695,888\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# multi-label classification therefore use binary_crossentropy\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'], run_eagerly=True)\n",
    "\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'],\n",
    "              run_eagerly=True)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use NN for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-14 07:38:43.653755: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 2720000000 exceeds 10% of free system memory.\n",
      "2022-12-14 07:38:44.018259: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 2720000000 exceeds 10% of free system memory.\n",
      "2022-12-14 07:38:44.380295: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 2720000000 exceeds 10% of free system memory.\n",
      "2022-12-14 07:38:49.790100: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 2720000000 exceeds 10% of free system memory.\n",
      "2022-12-14 07:38:50.548707: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 2720000000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - ETA: 0s - loss: 0.3988 - accuracy: 0.0168 \n",
      "Epoch 1: val_loss improved from inf to 0.29144, saving model to model.h5\n",
      "12/12 [==============================] - 126s 10s/step - loss: 0.3988 - accuracy: 0.0168 - val_loss: 0.2914 - val_accuracy: 0.0207 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2494 - accuracy: 0.0216 \n",
      "Epoch 2: val_loss improved from 0.29144 to 0.20774, saving model to model.h5\n",
      "12/12 [==============================] - 126s 11s/step - loss: 0.2494 - accuracy: 0.0216 - val_loss: 0.2077 - val_accuracy: 0.0207 - lr: 0.0010\n",
      "Epoch 3/10\n",
      " 1/12 [=>............................] - ETA: 1:56 - loss: 0.2082 - accuracy: 0.0300"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 24\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39m# model.fit_generator(\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39m#         train_batch, \u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39m#         steps_per_epoch=len(train_batch), # batch_size\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39m#   epochs=epochs\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[39m# )\u001b[39;00m\n\u001b[1;32m     23\u001b[0m epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m\n\u001b[0;32m---> 24\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     25\u001b[0m   train_ds\u001b[39m.\u001b[39;49mbatch(\u001b[39m500\u001b[39;49m),\n\u001b[1;32m     26\u001b[0m   validation_data\u001b[39m=\u001b[39;49mvalidation_ds\u001b[39m.\u001b[39;49mbatch(\u001b[39m50\u001b[39;49m),\n\u001b[1;32m     27\u001b[0m   epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m     28\u001b[0m   callbacks\u001b[39m=\u001b[39;49mcallbacks\n\u001b[1;32m     29\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1643\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1644\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1648\u001b[0m ):\n\u001b[1;32m   1649\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1650\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1651\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1652\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/training.py:1249\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m   1247\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_function\u001b[39m(iterator):\n\u001b[1;32m   1248\u001b[0m     \u001b[39m\"\"\"Runs a training execution with a single step.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1249\u001b[0m     \u001b[39mreturn\u001b[39;00m step_function(\u001b[39mself\u001b[39;49m, iterator)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/training.py:1233\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m   1229\u001b[0m     run_step \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mfunction(\n\u001b[1;32m   1230\u001b[0m         run_step, jit_compile\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, reduce_retracing\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1231\u001b[0m     )\n\u001b[1;32m   1232\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(iterator)\n\u001b[0;32m-> 1233\u001b[0m outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mdistribute_strategy\u001b[39m.\u001b[39;49mrun(run_step, args\u001b[39m=\u001b[39;49m(data,))\n\u001b[1;32m   1234\u001b[0m outputs \u001b[39m=\u001b[39m reduce_per_replica(\n\u001b[1;32m   1235\u001b[0m     outputs,\n\u001b[1;32m   1236\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy,\n\u001b[1;32m   1237\u001b[0m     reduction\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_reduction_method,\n\u001b[1;32m   1238\u001b[0m )\n\u001b[1;32m   1239\u001b[0m \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:1316\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1311\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscope():\n\u001b[1;32m   1312\u001b[0m   \u001b[39m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[1;32m   1313\u001b[0m   \u001b[39m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[1;32m   1314\u001b[0m   fn \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[1;32m   1315\u001b[0m       fn, autograph_ctx\u001b[39m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m-> 1316\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_extended\u001b[39m.\u001b[39;49mcall_for_each_replica(fn, args\u001b[39m=\u001b[39;49margs, kwargs\u001b[39m=\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:2895\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2893\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[1;32m   2894\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy()\u001b[39m.\u001b[39mscope():\n\u001b[0;32m-> 2895\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_for_each_replica(fn, args, kwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:3696\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3694\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_for_each_replica\u001b[39m(\u001b[39mself\u001b[39m, fn, args, kwargs):\n\u001b[1;32m   3695\u001b[0m   \u001b[39mwith\u001b[39;00m ReplicaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[0;32m-> 3696\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:595\u001b[0m, in \u001b[0;36mcall_with_unspecified_conversion_status.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    594\u001b[0m   \u001b[39mwith\u001b[39;00m ag_ctx\u001b[39m.\u001b[39mControlStatusCtx(status\u001b[39m=\u001b[39mag_ctx\u001b[39m.\u001b[39mStatus\u001b[39m.\u001b[39mUNSPECIFIED):\n\u001b[0;32m--> 595\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/training.py:1222\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1221\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_step\u001b[39m(data):\n\u001b[0;32m-> 1222\u001b[0m     outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtrain_step(data)\n\u001b[1;32m   1223\u001b[0m     \u001b[39m# Ensure counter is updated only if `train_step` succeeds.\u001b[39;00m\n\u001b[1;32m   1224\u001b[0m     \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/training.py:1027\u001b[0m, in \u001b[0;36mModel.train_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_target_and_loss(y, loss)\n\u001b[1;32m   1026\u001b[0m \u001b[39m# Run backwards pass.\u001b[39;00m\n\u001b[0;32m-> 1027\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer\u001b[39m.\u001b[39;49mminimize(loss, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainable_variables, tape\u001b[39m=\u001b[39;49mtape)\n\u001b[1;32m   1028\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_metrics(x, y, y_pred, sample_weight)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/optimizers/optimizer_experimental/optimizer.py:526\u001b[0m, in \u001b[0;36m_BaseOptimizer.minimize\u001b[0;34m(self, loss, var_list, tape)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mminimize\u001b[39m(\u001b[39mself\u001b[39m, loss, var_list, tape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    506\u001b[0m     \u001b[39m\"\"\"Minimize `loss` by updating `var_list`.\u001b[39;00m\n\u001b[1;32m    507\u001b[0m \n\u001b[1;32m    508\u001b[0m \u001b[39m    This method simply computes gradient using `tf.GradientTape` and calls\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[39m      None\u001b[39;00m\n\u001b[1;32m    525\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 526\u001b[0m     grads_and_vars \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_gradients(loss, var_list, tape)\n\u001b[1;32m    527\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_gradients(grads_and_vars)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/optimizers/optimizer_experimental/optimizer.py:259\u001b[0m, in \u001b[0;36m_BaseOptimizer.compute_gradients\u001b[0;34m(self, loss, var_list, tape)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[39mif\u001b[39;00m callable(var_list):\n\u001b[1;32m    257\u001b[0m             var_list \u001b[39m=\u001b[39m var_list()\n\u001b[0;32m--> 259\u001b[0m grads \u001b[39m=\u001b[39m tape\u001b[39m.\u001b[39;49mgradient(loss, var_list)\n\u001b[1;32m    260\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(grads, var_list))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/backprop.py:1112\u001b[0m, in \u001b[0;36mGradientTape.gradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1106\u001b[0m   output_gradients \u001b[39m=\u001b[39m (\n\u001b[1;32m   1107\u001b[0m       composite_tensor_gradient\u001b[39m.\u001b[39mget_flat_tensors_for_gradients(\n\u001b[1;32m   1108\u001b[0m           output_gradients))\n\u001b[1;32m   1109\u001b[0m   output_gradients \u001b[39m=\u001b[39m [\u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m x \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m ops\u001b[39m.\u001b[39mconvert_to_tensor(x)\n\u001b[1;32m   1110\u001b[0m                       \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m output_gradients]\n\u001b[0;32m-> 1112\u001b[0m flat_grad \u001b[39m=\u001b[39m imperative_grad\u001b[39m.\u001b[39;49mimperative_grad(\n\u001b[1;32m   1113\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tape,\n\u001b[1;32m   1114\u001b[0m     flat_targets,\n\u001b[1;32m   1115\u001b[0m     flat_sources,\n\u001b[1;32m   1116\u001b[0m     output_gradients\u001b[39m=\u001b[39;49moutput_gradients,\n\u001b[1;32m   1117\u001b[0m     sources_raw\u001b[39m=\u001b[39;49mflat_sources_raw,\n\u001b[1;32m   1118\u001b[0m     unconnected_gradients\u001b[39m=\u001b[39;49munconnected_gradients)\n\u001b[1;32m   1120\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_persistent:\n\u001b[1;32m   1121\u001b[0m   \u001b[39m# Keep track of watched variables before setting tape to None\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_watched_variables \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tape\u001b[39m.\u001b[39mwatched_variables()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/imperative_grad.py:67\u001b[0m, in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     65\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mUnknown value for unconnected_gradients: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m unconnected_gradients)\n\u001b[0;32m---> 67\u001b[0m \u001b[39mreturn\u001b[39;00m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_TapeGradient(\n\u001b[1;32m     68\u001b[0m     tape\u001b[39m.\u001b[39;49m_tape,  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m     69\u001b[0m     target,\n\u001b[1;32m     70\u001b[0m     sources,\n\u001b[1;32m     71\u001b[0m     output_gradients,\n\u001b[1;32m     72\u001b[0m     sources_raw,\n\u001b[1;32m     73\u001b[0m     compat\u001b[39m.\u001b[39;49mas_str(unconnected_gradients\u001b[39m.\u001b[39;49mvalue))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/backprop.py:157\u001b[0m, in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    155\u001b[0m     gradient_name_scope \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m forward_pass_name_scope \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    156\u001b[0m   \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mname_scope(gradient_name_scope):\n\u001b[0;32m--> 157\u001b[0m     \u001b[39mreturn\u001b[39;00m grad_fn(mock_op, \u001b[39m*\u001b[39;49mout_grads)\n\u001b[1;32m    158\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    159\u001b[0m   \u001b[39mreturn\u001b[39;00m grad_fn(mock_op, \u001b[39m*\u001b[39mout_grads)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/ops/nn_grad.py:678\u001b[0m, in \u001b[0;36m_MaxPoolGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[39m@ops\u001b[39m\u001b[39m.\u001b[39mRegisterGradient(\u001b[39m\"\u001b[39m\u001b[39mMaxPool\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    677\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_MaxPoolGrad\u001b[39m(op, grad):\n\u001b[0;32m--> 678\u001b[0m   \u001b[39mreturn\u001b[39;00m gen_nn_ops\u001b[39m.\u001b[39;49mmax_pool_grad(\n\u001b[1;32m    679\u001b[0m       op\u001b[39m.\u001b[39;49minputs[\u001b[39m0\u001b[39;49m],\n\u001b[1;32m    680\u001b[0m       op\u001b[39m.\u001b[39;49moutputs[\u001b[39m0\u001b[39;49m],\n\u001b[1;32m    681\u001b[0m       grad,\n\u001b[1;32m    682\u001b[0m       op\u001b[39m.\u001b[39;49mget_attr(\u001b[39m\"\u001b[39;49m\u001b[39mksize\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    683\u001b[0m       op\u001b[39m.\u001b[39;49mget_attr(\u001b[39m\"\u001b[39;49m\u001b[39mstrides\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    684\u001b[0m       padding\u001b[39m=\u001b[39;49mop\u001b[39m.\u001b[39;49mget_attr(\u001b[39m\"\u001b[39;49m\u001b[39mpadding\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    685\u001b[0m       explicit_paddings\u001b[39m=\u001b[39;49mop\u001b[39m.\u001b[39;49mget_attr(\u001b[39m\"\u001b[39;49m\u001b[39mexplicit_paddings\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    686\u001b[0m       data_format\u001b[39m=\u001b[39;49mop\u001b[39m.\u001b[39;49mget_attr(\u001b[39m\"\u001b[39;49m\u001b[39mdata_format\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/ops/gen_nn_ops.py:5990\u001b[0m, in \u001b[0;36mmax_pool_grad\u001b[0;34m(orig_input, orig_output, grad, ksize, strides, padding, explicit_paddings, data_format, name)\u001b[0m\n\u001b[1;32m   5988\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[1;32m   5989\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 5990\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[1;32m   5991\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mMaxPoolGrad\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, orig_input, orig_output, grad, \u001b[39m\"\u001b[39;49m\u001b[39mksize\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   5992\u001b[0m       ksize, \u001b[39m\"\u001b[39;49m\u001b[39mstrides\u001b[39;49m\u001b[39m\"\u001b[39;49m, strides, \u001b[39m\"\u001b[39;49m\u001b[39mpadding\u001b[39;49m\u001b[39m\"\u001b[39;49m, padding, \u001b[39m\"\u001b[39;49m\u001b[39mexplicit_paddings\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   5993\u001b[0m       explicit_paddings, \u001b[39m\"\u001b[39;49m\u001b[39mdata_format\u001b[39;49m\u001b[39m\"\u001b[39;49m, data_format)\n\u001b[1;32m   5994\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[1;32m   5995\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=10, verbose=1),\n",
    "    ReduceLROnPlateau(factor=0.1, patience=3, min_lr=0.00001, verbose=1),\n",
    "    ModelCheckpoint('model.h5', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "]\n",
    "\n",
    "# model.fit_generator(\n",
    "#         train_batch, \n",
    "#         steps_per_epoch=len(train_batch), # batch_size\n",
    "#         validation_data=test_batch,\n",
    "#         validation_steps=len(test_batch), # batch_size\n",
    "#         epochs=10,\n",
    "#         callbacks=callbacks\n",
    "#     )\n",
    "# epochs=10\n",
    "# history = model.fit(\n",
    "#   train_ds,\n",
    "#   validation_data=validation_ds,\n",
    "#   epochs=epochs\n",
    "# )\n",
    "epochs=10\n",
    "history = model.fit(\n",
    "  train_ds.batch(32),\n",
    "  validation_data=validation_ds.batch(32),\n",
    "  epochs=epochs,\n",
    "  callbacks=callbacks\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
